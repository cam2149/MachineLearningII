{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae716ef8",
   "metadata": {},
   "source": [
    "# Taller de modelos de clasificación utilizando KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3160290",
   "metadata": {},
   "source": [
    "El objetivo es que puedan asimilar el proceso de aprendizaje de modelos de aprendizaje supervisado (en este caso de clasificación). En este taller encontrarán código que deberán reproducir en sus propios ambientes de desarrollo. Incluye preguntas precisas; para responderlas tendrán que ejecutar el código, pues no todas las porciones de código del taller muestran los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c26cdb",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio (muy básico…)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cae86c",
   "metadata": {},
   "source": [
    "# Librerías a importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn import tree, datasets, neighbors, metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from sklearn import neighbors, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #método para evaluar varios particionamientos de C-V\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, LeaveOneOut #Iteradores de C-V\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31797ed",
   "metadata": {},
   "source": [
    "# Cargar y explorar el dataset de defaults de churn de clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641895a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('02-churn.csv', sep=';', na_values=\".\")\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a11eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18294e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffe5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LEAVE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LEAVE.describe()['freq'] / data.LEAVE.describe()['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e282997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LEAVE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LEAVE.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a6ef1",
   "metadata": {},
   "source": [
    "PREGUNTA: ¿Qué ven de particular en los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c912c0",
   "metadata": {},
   "source": [
    "# Repaso de acceso a características y datos de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:4,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b799d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.LEAVE.iloc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1558fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:10,[0,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0:10,['COLLEGE','HOUSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fccc2d",
   "metadata": {},
   "source": [
    "# Visualización de las distribuciones de las variables independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277eefd2",
   "metadata": {},
   "source": [
    "# Univariadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35bdbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.kdeplot(data[data['LEAVE']=='LEAVE']['HOUSE'], shade=True, color='r')\n",
    "sns.kdeplot(data[data['LEAVE']=='STAY']['HOUSE'], shade=True, color='g')\n",
    "plt.legend(['LEAVE', 'STAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.kdeplot(data[data['LEAVE']=='LEAVE']['OVERAGE'], shade=True, color='r')\n",
    "sns.kdeplot(data[data['LEAVE']=='STAY']['OVERAGE'], shade=True, color='g')\n",
    "plt.legend(['LEAVE', 'STAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.kdeplot(data[data['LEAVE']=='LEAVE']['INCOME'], shade=True, color='r')\n",
    "sns.kdeplot(data[data['LEAVE']=='STAY']['INCOME'], shade=True, color='g')\n",
    "plt.legend(['LEAVE', 'STAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4012f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.kdeplot(data[data['LEAVE']=='LEAVE']['LEFTOVER'], shade=True, color='r')\n",
    "sns.kdeplot(data[data['LEAVE']=='STAY']['LEFTOVER'], shade=True, color='g')\n",
    "plt.legend(['LEAVE', 'STAY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27c149",
   "metadata": {},
   "source": [
    "# Bivariadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e273c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"HOUSE\", y=\"OVERAGE\", hue=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11375fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"HOUSE\", y=\"INCOME\", hue=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"INCOME\", y=\"OVERAGE\", hue=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"LEFTOVER\", y=\"OVERAGE\", hue=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"HOUSE\", y=\"REPORTED_SATISFACTION\", hue=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c9707",
   "metadata": {},
   "source": [
    "# Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.pairplot(data,hue='LEAVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d23a33",
   "metadata": {},
   "source": [
    "# Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9618eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x=\"INCOME\", y=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a80c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x=\"LEFTOVER\", y=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x=\"HOUSE\", y=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9407d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x=\"OVERAGE\", y=\"LEAVE\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48971627",
   "metadata": {},
   "source": [
    "# 2. Proceso completo (Particionamiento + normalización + modelos KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b641cf",
   "metadata": {},
   "source": [
    "## Protocolos de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08b776",
   "metadata": {},
   "source": [
    "Vamos ahora a evaluar los modelos que calculamos con diferentes protocolos de evaluación para tener una idea más clara de la calidad de los mismos, e identificar posibles casos de modelos que sufren de overfitting (sobreaprendizaje)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0] #Se tienen 20000 filas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6ed17",
   "metadata": {},
   "source": [
    "Obtenemos las variables independientes numéricas y la variable dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b435b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericVars = data.iloc[:,1:8]\n",
    "depVar = data['LEAVE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc647be",
   "metadata": {},
   "source": [
    "## Holdout (split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c95477",
   "metadata": {},
   "source": [
    "Vamos a separar el dataset en 2 partes: 75% de los datos se van a utilizar para aprender, 25% para evaluar el modelo de clasificación. Utilizamos el método train_test_split de scikit-learn, que se encarga de hacer el particionamiento aleatorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(numericVars, depVar, random_state=1234, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacacad",
   "metadata": {},
   "source": [
    "Los parámetros de este método son:\n",
    "- train_size o test_size: define la proporción del dataset que se irán al training set o al test set.\n",
    "- random_state: define la **semilla** a utilizar para incializar el generador de números pseudo-aleatorios. Se requiere que los resultados obtenidos con la partición sean eventualmente reproducibles. La semilla aleatoria debe inicalizarse en el mismo valor para obtener los mismos resultados.\n",
    "- stratify: indica un array con los valores de una variable que se quiere tener en cuenta en el particionamiento, de tal manera que las proporciones originales se conserven después de la partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8adba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e99261",
   "metadata": {},
   "source": [
    "Vamos a reescalar las variables predictivas para que tengan la misma importancia, siguiendo un proceso de estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train.values\n",
    "x_std = StandardScaler().fit_transform(x)\n",
    "X_train_std = pd.DataFrame(x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test.values\n",
    "x_std = StandardScaler().fit_transform(x)\n",
    "X_test_std = pd.DataFrame(x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39ea2d",
   "metadata": {},
   "source": [
    "Entrenamos varios modelos knn para encontrar el k más apropiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_vec=[]\n",
    "acc_test_vec=[]\n",
    "k_vec= np.arange(1,31,2)\n",
    "for k in k_vec:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_std, y_train)\n",
    "    y_pred = knn.predict(X_train_std)\n",
    "    acc_train_vec.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = knn.predict(X_test_std)\n",
    "    acc_test_vec.append(metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Exactitud promedio (entrenamiento): %0.2f\" % np.mean(acc_train_vec))    \n",
    "print(\"Exactitud promedio (prueba): %0.2f\" % np.mean(acc_train_vec)) \n",
    "\n",
    "# Find the maximum accuracy and its index\n",
    "max_acc = max(acc_test_vec)\n",
    "max_acc_index = acc_test_vec.index(max_acc)\n",
    "\n",
    "# Get the corresponding k value\n",
    "k_best = k_vec[max_acc_index]\n",
    "\n",
    "print(f\"Maximum test accuracy: {max_acc:.4f}\")\n",
    "print(f\"Corresponding k value: {k_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(k_vec, acc_train_vec)\n",
    "plt.plot(k_vec, acc_test_vec)\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Evolución de le exactitud vs complejidad del modelo k-nn (valor de k más pequeño)')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd456aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_preds = knn.predict(X_train_std)\n",
    "print(\"Clases reales   : \", y_train)\n",
    "print(\"Clases predichas: \", y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9a790",
   "metadata": {},
   "source": [
    "Obtenemos la matriz de confusión sobre el mismo conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_train, y_preds)\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusion para k=27')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de0d0e",
   "metadata": {},
   "source": [
    "Encontramos los valores de exactitud, kappa, precisión, sensibilidad, especificidad y F1-score sobre los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ac1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitud: \", metrics.accuracy_score(y_train, y_preds))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_train, y_preds))\n",
    "print(\"Precisión     : \", metrics.precision_score(y_train, y_preds, labels=['LEAVE'], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_train, y_preds, labels=['LEAVE'], average='macro'))\n",
    "VN = cm[1,1]\n",
    "FP = cm[1,0]\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_train, y_preds, labels=['LEAVE'], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0554552",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = knn.predict(X_test_std)\n",
    "print(\"Clases reales   : \", y_test)\n",
    "print(\"Clases predichas: \", y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4519a35",
   "metadata": {},
   "source": [
    "Obtenemos la matriz de confusión sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusion para k=27')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df399c3c",
   "metadata": {},
   "source": [
    "Encontramos los valores de exactitud, kappa, precisión, sensibilidad, especificidad y F1-score sobre los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitud: \", metrics.accuracy_score(y_test, y_preds))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_test, y_preds))\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_preds, labels=['LEAVE'], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_preds, labels=['LEAVE'], average='macro'))\n",
    "VN = cm[1,1]\n",
    "FP = cm[1,0]\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_preds, labels=['LEAVE'], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e254c5",
   "metadata": {},
   "source": [
    "PREGUNTA: Intentemos el mismo proceso con otra semilla (otro particionamiento), por ejemplo con 3457. ¿Qué opinan de los resultados de los dos modelos? ¿Cómo explican las diferencias?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c2ca4",
   "metadata": {},
   "source": [
    "## K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3bc2c",
   "metadata": {},
   "source": [
    "Este protocolo de evaluación consiste en dividir el dataset en K pedazos de igual tamaño, y analizar el rendimiento de un modelo aprendido que va rotando sobre k-1 subconjuntos y evaluado en el subconjunto faltante (El K del K-fold no tiene niguna relación con el K del K-NN). \n",
    "En el caso de clasificación, particionamiento se hace aleatoriamente y de manera estratificada con respecto a la variable objetivo.\n",
    "Las métricas finales son las agregaciones de las evaluaciones de los K modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd1f23",
   "metadata": {},
   "source": [
    "#### cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d986a0",
   "metadata": {},
   "source": [
    "*scikit-learn* cuenta con una función que permite repetir el proceso de particionamiento y evaluación del K-fold CV. Se trata de **cross_val_score**, que recibe los siguientes parámetros:\n",
    "- la instancia del modelo que se quiere evaluar, \n",
    "- los datos de las variables independiente, \n",
    "- los datos reales de la variable dependiente, \n",
    "- cv: el número de veces que se va a repetir el proceso de cross-validation\n",
    "- scoring: la métrica que se desea evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7718b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numericVars.values\n",
    "x_std = StandardScaler().fit_transform(x)\n",
    "X_std = pd.DataFrame(x_std)\n",
    "y = depVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49317148",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "exactitudes = cross_val_score(knn, X_std, y, cv=10, scoring='accuracy')\n",
    "exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00752636",
   "metadata": {},
   "source": [
    "Vemos que los scores de las 10 iteraciones del CV dan resultados entre 66.6% y 69.9%. Podemos obtener un intervalo de confianza del 95% para estimar el valor de la exactitud generalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitudes: %0.2f (+/- %0.2f)\" % (exactitudes.mean(), exactitudes.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c4138",
   "metadata": {},
   "source": [
    "#### cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48334a1",
   "metadata": {},
   "source": [
    "El problema es que con este método solo se puede evaluar una sola métrica a la vez, y que debe ser una métrica global, o tratar una clasificación binaria.\n",
    "\n",
    "El método **cross_validate** permite evaluar mas de una métrica a la vez, pero en el caso de categorías que no sean binarias, las métricas de precision, recall y f1 son agregadas. La salida de este método es un directorio con las métricas resultantes, que además incluye el tiempo de aprendizaje y de evaluación de cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "scores = cross_validate(knn, X_std, y, scoring=scoring, cv=10, return_train_score=False)\n",
    "\n",
    "for key in scores:\n",
    "    score = scores[key]\n",
    "    print(\"%s: %0.2f (+/- %0.2f)\" % (key, score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27fed5",
   "metadata": {},
   "source": [
    "#### Iteradores de cross-validation: KFold, StratifiedKFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abe5df",
   "metadata": {},
   "source": [
    "Podemos utilizar también clases específicas para los particionamientos de los datos que permiten mucha más flexibilidad. Las clases **KFold**, **RepeatedKFold**, y **LeaveOneOut** se limitan a crear iteradores que retornan los subconjuntos de training y test.\n",
    "\n",
    "Es importante anotar que estos iteradores parten del supuesto de independencia de los registros, por lo que es necesario barajarlos previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb5b9b",
   "metadata": {},
   "source": [
    "KFold solo particiona los datos en subconjuntos de items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "acc_test_vec=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indices_train, indices_test in kf.split(X_std):\n",
    "    #print(\"%s %s\" % (indices_train, indices_test))\n",
    "    knn.fit(X_std.iloc[indices_train], y.iloc[indices_train])\n",
    "    y_pred = knn.predict(X_std.iloc[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y.iloc[indices_test], y_pred))  \n",
    "acc_test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0f944",
   "metadata": {},
   "source": [
    "Un caso particular es cuando el K del KFold es igual al tamaño de la muestra. En tal caso, se obtiene un protocolo de LeaveOneOut. En este caso los resultados para cada test set (de tamaño 1) solo pueden ser del 100% o del 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39357a50",
   "metadata": {},
   "source": [
    "### No correr este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "loocv = LeaveOneOut()\n",
    "acc_test_vec=[]\n",
    "for indices_train, indices_test in loocv.split(X_std):\n",
    "    #print(\"%s %s\" % (indices_train, indices_test))\n",
    "    knn.fit(X_std.iloc[indices_train], y.iloc[indices_train])\n",
    "    y_pred = knn.predict(X_std.iloc[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y[indices_test], y_pred))  \n",
    "np.mean(acc_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97725be6",
   "metadata": {},
   "source": [
    "Una mejora se logra con el StratifiedKFold, pues se tiene en cuenta las proporciones de la variable objetivo en la partición, controlando un poco un posible sesgo en la aleatoriedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "acc_test_vec=[]\n",
    "for indices_train, indices_test in kf.split(X_std, y):\n",
    "    knn.fit(X_std.iloc[indices_train], y.iloc[indices_train])\n",
    "    y_pred = knn.predict(X_std.iloc[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y.iloc[indices_test], y_pred))  \n",
    "acc_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d951bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "sfs = SequentialFeatureSelector(knn, k_features=5,        # Instead of n_features_to_select\n",
    "                              forward=True,        # True for forward selection\n",
    "                              floating=False,      \n",
    "                              scoring='accuracy',\n",
    "                              cv=5)\n",
    "sfs.fit(X_train_std,y_train)\n",
    "X_fs = sfs.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5035d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=27)\n",
    "knn.fit(X_fs,y_train)\n",
    "preds = knn.predict(X_fs)\n",
    "metrics.accuracy_score(y_train,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b9312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
